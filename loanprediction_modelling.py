# -*- coding: utf-8 -*-
"""LoanPrediction_Modelling.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1v4H4t1Ajvw67onijkiQxoCddBNRZLeJQ

# **Loan Prediction**

The aim of this project is to predict real-estate prices using the machine learning algorithms: Logistic Regression, Decision tree Classifier, Random Forest Classifier. The three of them will show different results for the accuracy.

# **Loading the data**
In the previous phase - Provisioning, data collection, data cleaning and data preparation were performed on a data scrpaed from website. In this file, this processed data will be used to train the models.

# **Modelling**
In this stage, I decided to use several models and eventually I can decide which one performed the best in order to use in the next phase - Deployment. I will explore the machine learning algorithms: Logistic Regression, Decision tree, Random Forest. All three will show different results for the accuracy. I decided to use these four models so as to check more features for comparing and different aspects. 

I will compare the models by calculating the MAE, MSE, RMSE and the accuracy.

# **Evaluation** 
After training the models, it is important for the next steps to find out how good the performance of the models is. Based on this, it will be possible to conclude whether Modelling & Evaluation is successful or not.

# **Imports**
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import requests
import matplotlib.pyplot as plt
import seaborn as sns
from google.colab import files
from datetime import datetime
import io
import mpl_toolkits
import numpy as np
# %matplotlib inline

# Load the data
local_file = files.upload()
train_data = io.BytesIO(local_file['results.csv'])
df = pd.read_csv(train_data)

"""# **Preparing the data for training the models**

Encoding to numeric data in order to start the training of the models.
"""

#drop the uniques loan id
df.drop('Loan_ID', axis = 1, inplace = True)

df.drop('Unnamed: 0', axis = 1, inplace = True)

df.info()

"""**Train-Test Split dataset**

Heatmaps are very useful to find relations between two variables in a dataset and this way the user gets a visualisation of the numeric data. No correlations are extremely high. Each square shows the correlation between the variables on each axis. 

*   The correlations between the feautures can be explained:


> The close to 1 the correlation is the more positively correlated they are; that is as one increases so does the other and the closer to 1 the stronger this relationship is. It is noticable that the correlation between the `ApplicantIncome` and `LoanAmount` is 0.57, which mean that they have a positive correlation, but not strong.
"""

# Commented out IPython magic to ensure Python compatibility.
from pandas import DataFrame
# %matplotlib inline
plt.figure(figsize=(12, 8))
df_temp = df.copy()
Index= ['Gender',	'Married',	'Dependents',	'Education',	'Self_Employed',	'ApplicantIncome',	'CoapplicantIncome',	'LoanAmount',	'Loan_Amount_Term',	'Credit_History',	'Property_Area',	'Loan_Status']
Cols = ['Gender',	'Married',	'Dependents',	'Education',	'Self_Employed',	'ApplicantIncome',	'CoapplicantIncome',	'LoanAmount',	'Loan_Amount_Term',	'Credit_History',	'Property_Area',	'Loan_Status']
df_temp = DataFrame(abs(np.random.randn(12, 12)), index=Index, columns=Cols)

sns.heatmap(df_temp.corr(), annot=True, cmap = 'magma')
plt.show()

"""Importing sklearn libraries"""

from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import f1_score
from sklearn.metrics import classification_report

"""Splitting into train and test set after choosing the right features X and labels y"""

y = df['Loan_Status']
X = df.drop('Loan_Status', axis = 1)

"""To split the dataset, I will use random sampling with 80/20 train-test split; that is, 80% of the dataset will be used for training and set aside 20% for testing:"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)

"""Analyzing the numeric features.

"""

numeric_features = df.select_dtypes(include=[np.number])

numeric_features.columns

# use only those input features with numeric data type 
df = df.select_dtypes(include=["int64","float64"])

# set the target and predictors
y = df.Loan_Status  # target

# use only those input features with numeric data type 
df_temp = df.select_dtypes(include=["int64","float64"]) 

X = df_temp.drop(["Loan_Status"],axis=1)  # predictors

"""# **Modeling**:

Three models will be built and evaluated by their performances with R-squared metric. Additionally, insights on the features that are strong predictors of house prices, will be analised .
"""

from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error

"""**Logistic Regression:**


1.  Creating 
2.  Fitting with train data




"""

model = LogisticRegression()
model.fit(X_train, y_train)

"""Root Mean Square Error (RMSE) is the standard deviation of the residuals (prediction errors). Residuals are a measure of how far from the regression line data points are; RMSE is a measure of how spread out these residuals are. In other words, it tells you how concentrated the data is around the line of best fit.
>RMSE values between 0.2 and 0.5 shows that the model can relatively predict the data accurately.
"""

# model evaluation for training set
y_train_r_predict = model.predict(X_train)
rmse = (np.sqrt(mean_squared_error(y_train, y_train_r_predict)))

print("The model performance for training set:")
print('RMSE is {}'.format(rmse))

"""Do predictions on a test set. **Testing** the model by testing the test data."""

#predict y_values using X_test set
y_reg=model.predict(X_test)

"""Comparing these metrics:

MAE is the easiest to understand because it’s the average error.
MSE is more popular than MAE because MSE “punishes” larger errors, which tends to be useful in the real world.
RMSE is even more popular than MSE because RMSE is interpretable in the “y” units.
"""

# model evaluation for testing set
print('MAE:', mean_absolute_error(y_test, y_reg)) 
print('MSE:', mean_squared_error(y_test, y_reg)) 
print('RMSE:', np.sqrt(mean_squared_error(y_test, y_reg)))

logistic_score =model.score((X_test),y_test)
print("Accuracy: ", logistic_score)

"""The F1 score can be interpreted as a weighted average of the precision and recall, where an F1 score reaches its best value at 1 and worst score at 0. """

evaluation = f1_score(y_test, y_reg)
evaluation

"""Reporting the coefficient value for each feature. Notice that the coefficients are both positive and negative. The positive scores indicate a feature that predicts class 1, whereas the negative scores indicate a feature that predicts class 0.

>The importance of a feature is measured by calculating the increase in the model's prediction error after permuting the feature. A feature is "important" if shuffling its values increases the model error, because in this case the model relied on the feature for the prediction.
"""

# get importance
importance = model.coef_[0]
# summarize feature importance
for i,v in enumerate(importance):
	print('Feature: %0d, Score: %.5f' % (i,v))
# plot feature importance
plt.bar([x for x in range(len(importance))], importance)
plt.show()

"""What coefficient of data says:

> It shows the relationship between the features. It is either positive or negative, depending ont the value shown on the graph. If it is below 0, it is a negative one, which means that whenever there is an increase in the value, there is a decrease in the price. What goes for the positive relationship - there is a parallel movement.

**Decision tree:**


1.  Creating classifier
2.  Fitting classifier with train data
"""

dtree = DecisionTreeClassifier()
dtree.fit(X_train, y_train)

# model evaluation for training set
y_train_r_predict = dtree.predict(X_train)
rmse = (np.sqrt(mean_squared_error(y_train, y_train_r_predict)))

print("The model performance for training set:")
print('RMSE is {}'.format(rmse))

"""Do predictions on a test set. **Testing** the model by testing the test data."""

y_tree=dtree.predict(X_test)

"""Comparing these metrics:

MAE is the easiest to understand because it’s the average error.
MSE is more popular than MAE because MSE “punishes” larger errors, which tends to be useful in the real world.
RMSE is even more popular than MSE because RMSE is interpretable in the “y” units.
"""

# model evaluation for testing set
print('MAE:', mean_absolute_error(y_test, y_tree)) 
print('MSE:', mean_squared_error(y_test, y_tree)) 
print('RMSE:', np.sqrt(mean_squared_error(y_test, y_tree)))

"""

> There is a 0.21 improvement, determining this from the MAE

"""

tree_score =dtree.score((X_test),y_test)
print("Accuracy: ", tree_score)

"""The F1 score can be interpreted as a weighted average of the precision and recall, where an F1 score reaches its best value at 1 and worst score at 0. """

evaluation = f1_score(y_test, y_tree)
evaluation

"""> Evaluate classsifier measures accuracy by using F1 score. The result shows that the model is precise.

**Random forests**

Grid search (not finished)
"""

# Feature Scaling
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV

sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

from sklearn.pipeline import Pipeline
pipe = Pipeline([('scaler', StandardScaler()), ('rf', RandomForestClassifier)])

params={
    'rf_n_est': [120, 140],
    'rf_max_depth': [30, 50],
    'rf_min_samples_split': [2, 3],
    'rf_min_samples_leaf': [3, 5],
    'rf_class_weight': [{0:1,1:1}, {0:1,1:5}, {0:1,1:3}, 'balanced']
}

"""End of grid search"""

rf = RandomForestClassifier()
rf.fit(X_train, y_train)

y_forest=rf.predict(X_test)

"""Comparing these metrics:

MAE is the easiest to understand because it’s the average error.
MSE is more popular than MAE because MSE “punishes” larger errors, which tends to be useful in the real world.
RMSE is even more popular than MSE because RMSE is interpretable in the “y” units.
"""

from sklearn import metrics

print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))
print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))
print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))

# Use the forest's predict method on the test data
predictions = rf.predict(X_test)
# Calculate the absolute errors
errors = abs(predictions - y_test)
# Print out the mean absolute error (mae)
print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')

"""

> There is a 0.15 improvement.

"""

# Calculate mean absolute percentage error (MAPE)
mape = 100 * (errors /y_test)
# Calculate and display accuracy
accuracy = 100 - np.mean(mape)
print('Accuracy:', round(accuracy, 2), '%.')

#Random forest determined feature importances
rf.feature_importances_

"""The F1 score can be interpreted as a weighted average of the precision and recall, where an F1 score reaches its best value at 1 and worst score at 0.

Result:
"""

evaluation_f= f1_score(y_test, y_forest)
evaluation_f

"""> After using the F1, it is determined that the model is precised to be used in the deployment.

# **Feature importance**
"""

importance = rf.feature_importances_

# map feature importance values to the features
feature_importances = zip(importance, X.columns)

#list(feature_importances)
sorted_feature_importances = sorted(feature_importances, reverse = True)

#print(sorted_feature_importances)
top_15_predictors = sorted_feature_importances[0:15]
values = [value for value, predictors in top_15_predictors]
predictors = [predictors for value, predictors in top_15_predictors]
print(predictors)

"""Saving the model that I am going to use in the deployment phase of the project"""

# Saving the model
import pickle

filename = 'classifier.pkl'
pickle.dump(forest, open(filename, 'wb'))

"""# Conclusion
I used three models to determine the accuracy - Logistic Regression, Decision Tree and Random Forest.

From the exploring of the models RMSE:

* Linear Regression score: 0.44

* Decision Tree score: 0.46

* Random forest score: 0.36

> RMSE values between 0.2 and 0.5 shows that the model can relatively predict the data accurately. All of the models showed values in this range.

From the exploring of the models accuracy: 

* Linear Regression score:  0.73 (73%)

* Decision Tree score: 0.79 (79%)

* Random forest score: 91.91 %

From the exploring of the models after the F1 score validation:  

* Linear Regression score: 0.89

* Decision Tree score: 0.6532616143265344

* Random forest: 0.91

Random forest turns out to be the more accurate model for predicting the house price. 

All of the models showed RMSE values between 0.2 and 0.5 so that they show  relatively accurate predictions of the data. 

I evaluated the models performances with F1 score metric and the one that is overfitting the least is the Random forest.

In the end, I tried three different models and evaluated them using Mean Absolute Error. I chose MAE because it is relatively easy to interpret and outliers aren’t particularly bad in for this type of model. The one I will be using for the deplyment is the  **Random forest**.



"""